# Model Performance Metrics, Twitter dataset, pre-trained on sampler version.

## experience 1: initial seeds (like report of paper)

| Model               | AUC    | TP    | FP    | FN    | TN     | F1      | Accuracy | (TN+FN)/Total ideal: 0.6629 | Precision | Recall | FPR     | TNR     | Runtime |
|---------------------|--------|-------|-------|-------|--------|---------|----------|-------------------|-----------|--------|---------|---------|---------|
| SybilGAT_L2 | 0.8311 | 71817 | 82256 | 5250  | 69315  | 0.6214  | 0.6173               | 0.3261            | 0.4661    | 0.9319 | 0.5427  | 0.4573  | 12420   |
| SybilGAT_L4 | 0.8464 | 71766 | 75360 | 5301  | 76211  | 0.6402  | 0.6472               | 0.3565            | 0.4878    | 0.9312 | 0.4972  | 0.5028  | 19476   |
| SybilGCNAli | 0.7959 | 56748 | 58120 | 20319 | 93451  | 0.5913  | 0.6569               | 0.4976            | 0.4940    | 0.7363 | 0.3835  | 0.6165  | 11433   |
| SybilRank   | 0.7415 | 64807 | 54257 | 12260 | 97314  | 0.6609  | 0.7091               | 0.4792            | 0.5443    | 0.8409 | 0.3580  | 0.6420  | 27705   |
| SybilBelief | 0.5821 | 16141 | 1266  | 60926 | 150305 | 0.3417  | 0.7280               | 0.9239            | 0.9273    | 0.2094 | 0.0084  | 0.9916  | 38012   |
| SybilSCAR   | 0.8090 | 2559  | 945   | 74508 | 150626 | 0.0635  | 0.6700               | 0.9847            | 0.7303    | 0.0332 | 0.0062  | 0.9938  | 30769   |


## experience 2: set solid seed to make experiment same from now on

| Model               | AUC    | TP    | FP    | FN    | TN     | F1      | Accuracy | (TN+FN)/Total ideal: 0.6629 | Precision | Recall | FPR     | TNR     | Runtime |
|---------------------|--------|-------|-------|-------|--------|---------|----------|-----------------------------|-----------|--------|---------|---------|---------|
| SybilGAT_L2         | 0.8320 | 72919 | 83980 | 4666  | 67130  | 0.6220  | 0.6124   | 0.3261                      | 0.4648    | 0.9399 | 0.5558  | 0.4442  | 16483   |
| SybilGAT_L4         | 0.8552 | 68945 | 65876 | 8640  | 85234  | 0.6492  | 0.6742   | 0.3565                      | 0.5114    | 0.8886 | 0.4359  | 0.5641  | 23895   |
| SybilGCNAli         | 0.8025 | 58894 | 61086 | 18691 | 90024  | 0.5962  | 0.6512   | 0.4976                      | 0.4909    | 0.7591 | 0.4042  | 0.5958  | 12430   |


## experience 3: without any edge in testset:

| Model               | AUC    | TP    | FP    | FN    | TN     | F1      | Accuracy | (TN+FN)/Total | Precision | Recall | FPR     | TNR     | Runtime |
|---------------------|--------|-------|-------|-------|--------|---------|----------|---------------|-----------|--------|---------|---------|---------|
| Model_1            | 0.6015 | 0     | 0     | 77585 | 151110 | 0.0000  | 0.6607   | 1.0000        | inf       | 0.0000 | 0.0000  | 1.0000  | 14865   |
| Model_2            | 0.6015 | 0     | 0     | 77585 | 151110 | 0.0000  | 0.6607   | 1.0000        | inf       | 0.0000 | 0.0000  | 1.0000  | 17696   |
| Model_3            | 0.6015 | 0     | 0     | 77585 | 151110 | 0.0000  | 0.6607   | 1.0000        | inf       | 0.0000 | 0.0000  | 1.0000  | 15387   |
| Model_4            | 0.5000 | 19571 | 90220 | 58014 | 60890  | 0.2089  | 0.3518   | 0.6511        | 0.1783    | 0.2523 | 0.5970  | 0.4030  | 8510    |
| Model_5            | 0.6015 | 0     | 0     | 77585 | 151110 | 0.0000  | 0.6607   | 1.0000        | inf       | 0.0000 | 0.0000  | 1.0000  | 2080    |
| Model_6            | 0.6015 | 0     | 0     | 77585 | 151110 | 0.0000  | 0.6607   | 1.0000        | inf       | 0.0000 | 0.0000  | 1.0000  | 732     |
