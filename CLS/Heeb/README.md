# Model Performance Metrics, Twitter dataset, pre-trained on sampler version.

## experience 1: initial seeds (like report of paper)

| Model               | AUC    | TP    | FP    | FN    | TN     | F1      | Accuracy | (TN+FN)/Total ideal: 0.6629 | Precision | Recall | FPR     | TNR     | Runtime |
|---------------------|--------|-------|-------|-------|--------|---------|----------|-------------------|-----------|--------|---------|---------|---------|
| SybilGAT_L2 | 0.8311 | 71817 | 82256 | 5250  | 69315  | 0.6214  | 0.6173               | 0.3261            | 0.4661    | 0.9319 | 0.5427  | 0.4573  | 12420   |
| SybilGAT_L4 | 0.8464 | 71766 | 75360 | 5301  | 76211  | 0.6402  | 0.6472               | 0.3565            | 0.4878    | 0.9312 | 0.4972  | 0.5028  | 19476   |
| SybilGCNAli | 0.7959 | 56748 | 58120 | 20319 | 93451  | 0.5913  | 0.6569               | 0.4976            | 0.4940    | 0.7363 | 0.3835  | 0.6165  | 11433   |
| SybilRank   | 0.7415 | 64807 | 54257 | 12260 | 97314  | 0.6609  | 0.7091               | 0.4792            | 0.5443    | 0.8409 | 0.3580  | 0.6420  | 27705   |
| SybilBelief | 0.5821 | 16141 | 1266  | 60926 | 150305 | 0.3417  | 0.7280               | 0.9239            | 0.9273    | 0.2094 | 0.0084  | 0.9916  | 38012   |
| SybilSCAR   | 0.8090 | 2559  | 945   | 74508 | 150626 | 0.0635  | 0.6700               | 0.9847            | 0.7303    | 0.0332 | 0.0062  | 0.9938  | 30769   |


## experiment: 1000 add 1000 remove in target
| Model         | AUC    | TP    | FP    | FN    | TN     | F1      | Accuracy | (TN+FN)/Total | Precision | Recall | FPR    | TNR    | Runtime |
|---------------|--------|-------|-------|-------|--------|---------|----------|---------------|-----------|--------|--------|--------|---------|
| SybilGAT_L2   | 0.8322 | 72928 | 83978 | 4657  | 67132  | 0.6220  | 0.6124   | 0.3139        | 0.4648    | 0.9400 | 0.5557 | 0.4443 | 13594   |
| SybilGAT_L4   | 0.8554 | 69002 | 65946 | 8583  | 85164  | 0.6493  | 0.6741   | 0.4099        | 0.5113    | 0.8894 | 0.4364 | 0.5636 | 27434   |
| SybilGCNAli   | 0.8026 | 58934 | 61088 | 18651 | 90022  | 0.5965  | 0.6513   | 0.4752        | 0.4910    | 0.7596 | 0.4043 | 0.5957 | 12672   |
| SybilRank     | 0.7277 | 64402 | 54764 | 13183 | 96346  | 0.6547  | 0.7029   | 0.4789        | 0.5404    | 0.8301 | 0.3624 | 0.6376 | 29422   |
| SybilBelief   | 0.6246 | 21977 | 1728  | 55608 | 149382 | 0.4339  | 0.7493   | 0.8963        | 0.9271    | 0.2833 | 0.0114 | 0.9886 | 771937  |
| SybilSCAR     | 0.8079 | 3897  | 1335  | 73688 | 149775 | 0.0941  | 0.6720   | 0.9771        | 0.7448    | 0.0502 | 0.0088 | 0.9912 | 22606   |




## experience 2: set solid seed to make experiment same from now on

| Model               | AUC    | TP    | FP    | FN    | TN     | F1      | Accuracy | (TN+FN)/Total ideal: 0.6629 | Precision | Recall | FPR     | TNR     | Runtime |
|---------------------|--------|-------|-------|-------|--------|---------|----------|-----------------------------|-----------|--------|---------|---------|---------|
| SybilGAT_L2         | 0.8320 | 72919 | 83980 | 4666  | 67130  | 0.6220  | 0.6124   | 0.3261                      | 0.4648    | 0.9399 | 0.5558  | 0.4442  | 16483   |
| SybilGAT_L4         | 0.8552 | 68945 | 65876 | 8640  | 85234  | 0.6492  | 0.6742   | 0.3565                      | 0.5114    | 0.8886 | 0.4359  | 0.5641  | 23895   |
| SybilGCNAli         | 0.8025 | 58894 | 61086 | 18691 | 90024  | 0.5962  | 0.6512   | 0.4976                      | 0.4909    | 0.7591 | 0.4042  | 0.5958  | 12430   |


## experience 3: without any edge in testset:

| Model               | AUC    | TP    | FP    | FN    | TN     | F1      | Accuracy | (TN+FN)/Total | Precision | Recall | FPR     | TNR     | Runtime |
|---------------------|--------|-------|-------|-------|--------|---------|----------|---------------|-----------|--------|---------|---------|---------|
| Model_1            | 0.6015 | 0     | 0     | 77585 | 151110 | 0.0000  | 0.6607   | 1.0000        | inf       | 0.0000 | 0.0000  | 1.0000  | 14865   |
| Model_2            | 0.6015 | 0     | 0     | 77585 | 151110 | 0.0000  | 0.6607   | 1.0000        | inf       | 0.0000 | 0.0000  | 1.0000  | 17696   |
| Model_3            | 0.6015 | 0     | 0     | 77585 | 151110 | 0.0000  | 0.6607   | 1.0000        | inf       | 0.0000 | 0.0000  | 1.0000  | 15387   |
| Model_4            | 0.5000 | 19571 | 90220 | 58014 | 60890  | 0.2089  | 0.3518   | 0.6511        | 0.1783    | 0.2523 | 0.5970  | 0.4030  | 8510    |
| Model_5            | 0.6015 | 0     | 0     | 77585 | 151110 | 0.0000  | 0.6607   | 1.0000        | inf       | 0.0000 | 0.0000  | 1.0000  | 2080    |
| Model_6            | 0.6015 | 0     | 0     | 77585 | 151110 | 0.0000  | 0.6607   | 1.0000        | inf       | 0.0000 | 0.0000  | 1.0000  | 732     |



### Metrics

### Metrics

In classification tasks, we evaluate the model performance using **Precision**, **Recall**, and **F1-score**.

- **Precision**: Measures the accuracy of positive predictions.
  
  Precision = TP / (TP + FP)

- **Recall**: Measures the coverage of actual positives.
  
  Recall = TP / (TP + FN)

- **F1-Score**: The harmonic mean of Precision and Recall.
  
  F1-Score = 2 * (Precision * Recall) / (Precision + Recall)
