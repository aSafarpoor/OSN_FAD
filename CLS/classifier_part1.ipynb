{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9f0B/15tMZksZSLYYrYR5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aSafarpoor/OSN_FAD/blob/main/CLS/classifier_part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#read data"
      ],
      "metadata": {
        "id": "xmAcn1bjPL4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "Av4Sn1X2f9-w"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "t5mRRc34eyhA"
      },
      "outputs": [],
      "source": [
        "def load_txt_file(filename):\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\treturn [int(line.strip()) for line in file]\n",
        "\n",
        "def load_txt_file_for_edges(filename):\n",
        "\twith open(filename, 'r') as file:\n",
        "\t\treturn [list(map(int,line.strip().split())) for line in file]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def partitioner(x):\n",
        "    midpoint = len(x) // 2\n",
        "\n",
        "    # Split the list into two parts\n",
        "    return x[:midpoint], x[midpoint:]"
      ],
      "metadata": {
        "id": "5DUzSzWlUMNB"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edges = load_txt_file_for_edges('edges.txt')\n",
        "\n",
        "\n",
        "bknown = load_txt_file('btrain.txt')\n",
        "sknown = load_txt_file('strain.txt')\n",
        "\n",
        "b_known_in_test_phase,btrain = partitioner(bknown)\n",
        "s_known_in_test_phase,strain = partitioner(sknown)\n",
        "\n",
        "\n",
        "btest = load_txt_file('btest.txt')\n",
        "stest = load_txt_file('stest.txt')\n",
        "nodes = list(set(np.array(edges).reshape(-1)))\n",
        "num_nodes = len(nodes)\n",
        "\n",
        "print(len(bknown),len(sknown),len(btest),len(stest))"
      ],
      "metadata": {
        "id": "wwpiM2hPezZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aebe584-a49b-4371-fe5f-0f82a2d4d9bf"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80 80 323 323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Transductive"
      ],
      "metadata": {
        "id": "t_98W0QGg-XV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
        "!pip install torch\n",
        "!pip install torch-geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EewAes2_g90b",
        "outputId": "321b599a-7644-4a9b-b404-7936f59a0333"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric) (0.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data\n",
        "import torch_geometric.utils as pyg_utils\n",
        "from torch_geometric.nn import GATConv\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from torch_geometric.utils import subgraph"
      ],
      "metadata": {
        "id": "qkU4TKqhezeG"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN_ETH(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, num_layers, hidden_width, dropout = True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        input_width = num_node_features\n",
        "        self.num_classes = 2\n",
        "        for i in range(num_layers):\n",
        "            if i == 0:\n",
        "                self.convs.append(GCNConv(input_width, hidden_width, bias=False))\n",
        "            elif i == num_layers - 1:\n",
        "                self.convs.append(GCNConv(hidden_width, self.num_classes, bias=False))\n",
        "            else:\n",
        "                self.convs.append(GCNConv(hidden_width, hidden_width, bias=False))\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        h = x\n",
        "        i = 0\n",
        "        for conv in self.convs:\n",
        "            if self.dropout:\n",
        "                h = F.dropout(h, p=0.5, training=self.training)\n",
        "            h = conv(h, edge_index)\n",
        "            if i < len(self.convs) - 1:\n",
        "                h = F.tanh(h)\n",
        "            i += 1\n",
        "\n",
        "        return F.log_softmax(h, dim=1)\n"
      ],
      "metadata": {
        "id": "OvLYPRvB3hq2"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Edited_GCN_ETH(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, num_layers, hidden_width, dropout=True):\n",
        "        super(Edited_GCN_ETH, self).__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        input_width = num_node_features\n",
        "        self.num_classes = 2  # Assuming binary classification\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            if i == 0:  # First layer\n",
        "                self.convs.append(GCNConv(input_width, hidden_width, bias=True))\n",
        "            elif i == num_layers - 1:  # Last layer\n",
        "                self.convs.append(GCNConv(hidden_width, self.num_classes, bias=True))\n",
        "            else:  # Hidden layers\n",
        "                self.convs.append(GCNConv(hidden_width, hidden_width, bias=True))\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        h = x\n",
        "\n",
        "        for i, conv in enumerate(self.convs):\n",
        "            h = conv(h, edge_index)\n",
        "\n",
        "            if i < len(self.convs) - 1:  # Apply activation and dropout for all but last layer\n",
        "                h = F.relu(h)\n",
        "                if self.dropout:\n",
        "                    h = F.dropout(h, p=0.5, training=self.training)\n",
        "\n",
        "        return F.log_softmax(h, dim=1)"
      ],
      "metadata": {
        "id": "6VRhixPqWVcH"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT_ETH(torch.nn.Module):\n",
        "    def __init__(self, input_width, num_layers, hidden_width, num_classes, num_heads, dropout: bool = True):\n",
        "        super().__init__()\n",
        "        self.dropout = dropout\n",
        "        self.num_classes = num_classes\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            if i == 0:  # First layer\n",
        "                self.convs.append(GATConv(input_width, hidden_width, heads=num_heads))\n",
        "            elif i == num_layers - 1:  # Last layer\n",
        "                self.convs.append(GATConv(hidden_width * num_heads, self.num_classes, heads=1))\n",
        "            else:  # Middle layers\n",
        "                self.convs.append(GATConv(hidden_width * num_heads, hidden_width, heads=num_heads))\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        # x = self.conv1(x, edge_index)\n",
        "        # # x = F.elu(x)\n",
        "        # x = F.tanh(x)\n",
        "        # x = self.conv2(x, edge_index)\n",
        "        # h = x\n",
        "\n",
        "        h = x\n",
        "        i = 0\n",
        "        for conv in self.convs:\n",
        "            if self.dropout:\n",
        "                h = F.dropout(h, p=0.5, training=self.training)\n",
        "            h = conv(h, edge_index)\n",
        "            if i < len(self.convs) - 1:\n",
        "                h = F.tanh(h)\n",
        "                # h = F.elu(h)\n",
        "            i += 1\n",
        "\n",
        "        return F.log_softmax(h, dim=1)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "_r--rexV4MGo"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN1(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, hidden_dim, num_classes):\n",
        "        super(GCN1, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_dim)\n",
        "        self.conv2 = GCNConv(hidden_dim, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "kd6aMRFVezoO"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN2(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, hidden_dim1, hidden_dim2, num_classes):\n",
        "        super(GCN2, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, hidden_dim1)\n",
        "        self.conv2 = GCNConv(hidden_dim1, hidden_dim2)\n",
        "        self.conv3 = GCNConv(hidden_dim2, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.conv3(x, edge_index)\n",
        "        x = F.softmax(x,dim=1)\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "hMuQ41TZso4z"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT1(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, hidden_dim1, hidden_dim2, num_classes, num_heads=1):\n",
        "        super(GAT1, self).__init__()\n",
        "        self.gat1 = GATConv(num_node_features, hidden_dim1, heads=num_heads, concat=True)\n",
        "        self.gat2 = GATConv(hidden_dim1 * num_heads, hidden_dim2, heads=num_heads, concat=True)\n",
        "        self.gat3 = GATConv(hidden_dim2 * num_heads, num_classes, heads=1, concat=False)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.gat1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.gat2(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        x = self.gat3(x, edge_index)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "9RlOZyEMxwz4"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(1, 16)  # 1 input feature, 16 output features\n",
        "        self.conv2 = GCNConv(16, 2)  # 16 input features, 2 output features (binary classification)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "ZHrlHIuqEYIV"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main_transductive(model):\n",
        "\n",
        "    edge_index = torch.tensor([[e[0] for e in edges], [e[1] for e in edges]], dtype=torch.long)  # Replace with actual edges\n",
        "\n",
        "\n",
        "    # Assign labels (0 for benign, 1 for sybil)\n",
        "    labels = torch.tensor([0 if i in btrain or i in btest else 1 for i in range(num_nodes)])\n",
        "\n",
        "    # Initialize the node features\n",
        "    x = torch.zeros((num_nodes, 1))  # 1-dimensional embeddings, all zeros initially\n",
        "\n",
        "    # Assign initial embeddings based on the conditions\n",
        "    for node in btrain:\n",
        "        x[node] = 0  # Benign training nodes\n",
        "    for node in strain:\n",
        "        x[node] = 1  # Sybil training nodes\n",
        "    for node in btest + stest:\n",
        "        x[node] = 0.5  # Test nodes\n",
        "\n",
        "    # Create the PyTorch Geometric data object\n",
        "    data_train = Data(x=x, edge_index=edge_index, y=labels)\n",
        "\n",
        "\n",
        "    for node in b_known_in_test_phase:\n",
        "        x[node] = 0  # Benign training nodes\n",
        "    for node in s_known_in_test_phase:\n",
        "        x[node] = 1\n",
        "\n",
        "\n",
        "    data_test = Data(x=x, edge_index=edge_index, y=labels)\n",
        "\n",
        "\n",
        "    # Define optimizer and loss function\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Split data into training and testing masks\n",
        "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "\n",
        "    # Assign masks for training and testing nodes\n",
        "    train_mask[btrain + strain] = True\n",
        "    test_mask[btest + stest] = True\n",
        "\n",
        "    # Training loop\n",
        "    def train():\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data_train)\n",
        "        loss = loss_fn(out[train_mask], data_train.y[train_mask])  # Only consider training nodes for loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "    # Testing function\n",
        "    def test():\n",
        "        model.eval()\n",
        "        out = model(data_test)\n",
        "        pred = out.argmax(dim=1)  # Get predictions\n",
        "        train_acc = accuracy_score(data_test.y[train_mask].cpu(), pred[train_mask].cpu())\n",
        "        test_acc = accuracy_score(data_test.y[test_mask].cpu(), pred[test_mask].cpu())\n",
        "        return train_acc, test_acc\n",
        "\n",
        "    # Training the model\n",
        "    epochs = 100\n",
        "    for epoch in range(epochs):\n",
        "        loss = train()\n",
        "        train_acc, test_acc = test()\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch {epoch}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "    # Final evaluation\n",
        "    train_acc, test_acc = test()\n",
        "    print(f'Final Train Accuracy: {train_acc:.4f}, Final Test Accuracy: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "id": "w2SO_Ro26DM4"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GCN())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oECdI7kYEyPG",
        "outputId": "feb97a52-0521-474a-fc35-4225844b9970"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7117, Train Acc: 0.0750, Test Acc: 0.1223\n",
            "Epoch 10, Loss: 0.6859, Train Acc: 0.8375, Test Acc: 0.7755\n",
            "Epoch 20, Loss: 0.6720, Train Acc: 0.9000, Test Acc: 0.8452\n",
            "Epoch 30, Loss: 0.6549, Train Acc: 0.9250, Test Acc: 0.8715\n",
            "Epoch 40, Loss: 0.6320, Train Acc: 0.9125, Test Acc: 0.8653\n",
            "Epoch 50, Loss: 0.5994, Train Acc: 0.9250, Test Acc: 0.8653\n",
            "Epoch 60, Loss: 0.5558, Train Acc: 0.9375, Test Acc: 0.8700\n",
            "Epoch 70, Loss: 0.5000, Train Acc: 0.9375, Test Acc: 0.8839\n",
            "Epoch 80, Loss: 0.4301, Train Acc: 0.9375, Test Acc: 0.9009\n",
            "Epoch 90, Loss: 0.3482, Train Acc: 0.9750, Test Acc: 0.9365\n",
            "Final Train Accuracy: 0.9875, Final Test Accuracy: 0.9752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GCN1(num_node_features=1, hidden_dim=16, num_classes=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eE_DwdEsBn2V",
        "outputId": "c3501524-0bd9-4bbc-c5f8-794af0565c22"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6918, Train Acc: 0.6000, Test Acc: 0.5248\n",
            "Epoch 10, Loss: 0.6552, Train Acc: 0.9125, Test Acc: 0.8638\n",
            "Epoch 20, Loss: 0.6207, Train Acc: 0.9125, Test Acc: 0.8622\n",
            "Epoch 30, Loss: 0.5767, Train Acc: 0.9125, Test Acc: 0.8684\n",
            "Epoch 40, Loss: 0.5241, Train Acc: 0.9250, Test Acc: 0.8731\n",
            "Epoch 50, Loss: 0.4661, Train Acc: 0.9375, Test Acc: 0.8731\n",
            "Epoch 60, Loss: 0.4068, Train Acc: 0.9375, Test Acc: 0.8824\n",
            "Epoch 70, Loss: 0.3508, Train Acc: 0.9375, Test Acc: 0.8885\n",
            "Epoch 80, Loss: 0.3011, Train Acc: 0.9375, Test Acc: 0.8932\n",
            "Epoch 90, Loss: 0.2478, Train Acc: 0.9500, Test Acc: 0.9025\n",
            "Final Train Accuracy: 0.9625, Final Test Accuracy: 0.9211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GCN2(num_node_features=1, hidden_dim1=16, hidden_dim2 = 16, num_classes=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2MjqMzGCDsn",
        "outputId": "df93f18e-3776-4aec-f03d-8a68a467ebc8"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6938, Train Acc: 0.5000, Test Acc: 0.5015\n",
            "Epoch 10, Loss: 0.6812, Train Acc: 0.8875, Test Acc: 0.8483\n",
            "Epoch 20, Loss: 0.6590, Train Acc: 0.9500, Test Acc: 0.9133\n",
            "Epoch 30, Loss: 0.6121, Train Acc: 0.9625, Test Acc: 0.9226\n",
            "Epoch 40, Loss: 0.5349, Train Acc: 0.9625, Test Acc: 0.9257\n",
            "Epoch 50, Loss: 0.4472, Train Acc: 0.9625, Test Acc: 0.9180\n",
            "Epoch 60, Loss: 0.3929, Train Acc: 0.9625, Test Acc: 0.9241\n",
            "Epoch 70, Loss: 0.3708, Train Acc: 0.9625, Test Acc: 0.9257\n",
            "Epoch 80, Loss: 0.3624, Train Acc: 0.9625, Test Acc: 0.9257\n",
            "Epoch 90, Loss: 0.3589, Train Acc: 0.9625, Test Acc: 0.9241\n",
            "Final Train Accuracy: 0.9625, Final Test Accuracy: 0.9241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GCN_ETH(num_node_features=1, num_layers=4, hidden_width=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9C9qj3ECsBo",
        "outputId": "aaa964d0-d8aa-4973-cfcb-d2ec4f602810"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7014, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 10, Loss: 0.6670, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 20, Loss: 0.6694, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 30, Loss: 0.6686, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 40, Loss: 0.6679, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 50, Loss: 0.6641, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 60, Loss: 0.6688, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 70, Loss: 0.6648, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 80, Loss: 0.6670, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 90, Loss: 0.6626, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Final Train Accuracy: 0.5000, Final Test Accuracy: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(Edited_GCN_ETH(num_node_features=1, num_layers=3, hidden_width=16))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7RIXKZ2WY2l",
        "outputId": "0645c820-b5de-439e-bacc-7875bf25ed3b"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6925, Train Acc: 0.6500, Test Acc: 0.6517\n",
            "Epoch 10, Loss: 0.6544, Train Acc: 0.9375, Test Acc: 0.8777\n",
            "Epoch 20, Loss: 0.5520, Train Acc: 0.9125, Test Acc: 0.8731\n",
            "Epoch 30, Loss: 0.4787, Train Acc: 0.9500, Test Acc: 0.8978\n",
            "Epoch 40, Loss: 0.3201, Train Acc: 0.9625, Test Acc: 0.9164\n",
            "Epoch 50, Loss: 0.2598, Train Acc: 0.9625, Test Acc: 0.9241\n",
            "Epoch 60, Loss: 0.2638, Train Acc: 0.9625, Test Acc: 0.9180\n",
            "Epoch 70, Loss: 0.2056, Train Acc: 0.9625, Test Acc: 0.9195\n",
            "Epoch 80, Loss: 0.2126, Train Acc: 0.9625, Test Acc: 0.9241\n",
            "Epoch 90, Loss: 0.2219, Train Acc: 0.9625, Test Acc: 0.9350\n",
            "Final Train Accuracy: 0.9625, Final Test Accuracy: 0.9381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GAT1(num_node_features=1, hidden_dim1=16, hidden_dim2=16, num_classes=2, num_heads=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjzupYgGFBEQ",
        "outputId": "ea06d461-85eb-451f-907e-3bf72d4f527f"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6893, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 10, Loss: 0.4014, Train Acc: 0.9375, Test Acc: 0.9149\n",
            "Epoch 20, Loss: 0.1835, Train Acc: 0.9750, Test Acc: 0.9505\n",
            "Epoch 30, Loss: 0.1021, Train Acc: 0.9750, Test Acc: 0.9582\n",
            "Epoch 40, Loss: 0.0690, Train Acc: 0.9875, Test Acc: 0.9675\n",
            "Epoch 50, Loss: 0.0335, Train Acc: 1.0000, Test Acc: 0.9737\n",
            "Epoch 60, Loss: 0.0156, Train Acc: 1.0000, Test Acc: 0.9706\n",
            "Epoch 70, Loss: 0.0086, Train Acc: 1.0000, Test Acc: 0.9721\n",
            "Epoch 80, Loss: 0.0059, Train Acc: 1.0000, Test Acc: 0.9768\n",
            "Epoch 90, Loss: 0.0046, Train Acc: 1.0000, Test Acc: 0.9752\n",
            "Final Train Accuracy: 1.0000, Final Test Accuracy: 0.9752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GAT_ETH(input_width=1, num_layers=4, hidden_width=16, num_classes=2, num_heads=8, dropout= True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYnE_pmhGPxt",
        "outputId": "9031d718-b013-4f9b-ecb8-be26d6960850"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6941, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 10, Loss: 0.9730, Train Acc: 0.6125, Test Acc: 0.5712\n",
            "Epoch 20, Loss: 0.4364, Train Acc: 0.8000, Test Acc: 0.7136\n",
            "Epoch 30, Loss: 0.2396, Train Acc: 0.9500, Test Acc: 0.9257\n",
            "Epoch 40, Loss: 0.2189, Train Acc: 0.6375, Test Acc: 0.5851\n",
            "Epoch 50, Loss: 0.5130, Train Acc: 0.9375, Test Acc: 0.8715\n",
            "Epoch 60, Loss: 0.2382, Train Acc: 0.6625, Test Acc: 0.6223\n",
            "Epoch 70, Loss: 0.3395, Train Acc: 0.8375, Test Acc: 0.7678\n",
            "Epoch 80, Loss: 0.2723, Train Acc: 0.9500, Test Acc: 0.9241\n",
            "Epoch 90, Loss: 0.2028, Train Acc: 0.9375, Test Acc: 0.9365\n",
            "Final Train Accuracy: 0.7750, Final Test Accuracy: 0.7059\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GAT1(num_node_features=1, hidden_dim1=4, hidden_dim2=4, num_classes=2, num_heads=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMwO2FKuGk3n",
        "outputId": "b34e9e2d-9cfb-40ca-8b0b-bc15d953f679"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.7000, Train Acc: 0.5000, Test Acc: 0.5000\n",
            "Epoch 10, Loss: 0.6393, Train Acc: 0.9000, Test Acc: 0.8591\n",
            "Epoch 20, Loss: 0.5146, Train Acc: 0.9375, Test Acc: 0.8901\n",
            "Epoch 30, Loss: 0.3501, Train Acc: 0.9000, Test Acc: 0.8808\n",
            "Epoch 40, Loss: 0.2544, Train Acc: 0.9375, Test Acc: 0.9102\n",
            "Epoch 50, Loss: 0.2135, Train Acc: 0.9375, Test Acc: 0.9288\n",
            "Epoch 60, Loss: 0.1774, Train Acc: 0.9500, Test Acc: 0.9489\n",
            "Epoch 70, Loss: 0.1264, Train Acc: 0.9625, Test Acc: 0.9644\n",
            "Epoch 80, Loss: 0.0448, Train Acc: 0.9750, Test Acc: 0.9783\n",
            "Epoch 90, Loss: 0.0067, Train Acc: 1.0000, Test Acc: 0.9861\n",
            "Final Train Accuracy: 1.0000, Final Test Accuracy: 0.9845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_transductive(GCN2(num_node_features=1, hidden_dim1=6, hidden_dim2 = 6, num_classes=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jr-H6z3LlKN",
        "outputId": "c1ff5520-f275-46bd-a351-5b14df25998a"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6891, Train Acc: 0.6500, Test Acc: 0.6130\n",
            "Epoch 10, Loss: 0.6824, Train Acc: 0.8250, Test Acc: 0.7910\n",
            "Epoch 20, Loss: 0.6714, Train Acc: 0.8125, Test Acc: 0.7693\n",
            "Epoch 30, Loss: 0.6544, Train Acc: 0.8500, Test Acc: 0.7786\n",
            "Epoch 40, Loss: 0.6296, Train Acc: 0.8500, Test Acc: 0.7833\n",
            "Epoch 50, Loss: 0.5944, Train Acc: 0.8500, Test Acc: 0.8019\n",
            "Epoch 60, Loss: 0.5508, Train Acc: 0.8625, Test Acc: 0.8297\n",
            "Epoch 70, Loss: 0.5097, Train Acc: 0.8750, Test Acc: 0.8452\n",
            "Epoch 80, Loss: 0.4757, Train Acc: 0.8875, Test Acc: 0.8638\n",
            "Epoch 90, Loss: 0.4482, Train Acc: 0.8875, Test Acc: 0.8715\n",
            "Final Train Accuracy: 0.9125, Final Test Accuracy: 0.8808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#inductive"
      ],
      "metadata": {
        "id": "EWjp8CKGPbuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def create_subgraph(data, nodes_subset):\n",
        "\n",
        "    # Convert nodes_subset to tensor\n",
        "    nodes_subset = torch.tensor(nodes_subset, dtype=torch.long)\n",
        "\n",
        "    # Create a subgraph with only the edges between nodes in nodes_subset\n",
        "    edge_index, edge_attr = subgraph(nodes_subset, data.edge_index, relabel_nodes=True)\n",
        "\n",
        "    # Select the corresponding node features\n",
        "    x = data.x[nodes_subset]\n",
        "\n",
        "    # Select the corresponding labels (if any)\n",
        "    y = data.y[nodes_subset] #if data.y is not None else None\n",
        "\n",
        "    # Return the subgraph\n",
        "    subgraph_data = Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "    return subgraph_data\n",
        "\n",
        "\n",
        "def main_inductive(model):\n",
        "\n",
        "    edge_index = torch.tensor([[e[0] for e in edges], [e[1] for e in edges]], dtype=torch.long)  # Replace with actual edges\n",
        "\n",
        "    # Define the set of unknown nodes (nodes not in btrain, strain, btest, stest)\n",
        "    known_nodes = set(btrain + strain + btest + stest)\n",
        "    unknown_nodes = list(set(range(num_nodes)) - known_nodes)\n",
        "\n",
        "    # Sample 1/4 of unknown nodes for TRAIN\n",
        "    random.shuffle(unknown_nodes)\n",
        "    unknown_sample_for_train = unknown_nodes[:len(unknown_nodes)//4]\n",
        "    print(len(unknown_sample_for_train),len(unknown_sample_for_train))\n",
        "    # Create subgraph TRAIN consisting of btrain, strain, and 1/4 of unknown nodes\n",
        "    train_nodes = btrain + strain + unknown_sample_for_train\n",
        "\n",
        "    # Create subgraph TEST consisting of the remaining nodes\n",
        "    test_nodes = list(set(nodes) - set(train_nodes))\n",
        "\n",
        "    # Assign labels (0 for benign, 1 for sybil)\n",
        "    labels = torch.tensor([0 if i in btrain\n",
        "                           or i in btest\n",
        "                           or i in  b_known_in_test_phase else 1 for i in range(num_nodes)])\n",
        "\n",
        "\n",
        "\n",
        "    # Initialize the node features\n",
        "    x = torch.zeros((num_nodes, 1))  # 1-dimensional embeddings, all zeros initially\n",
        "\n",
        "    # Assign initial embeddings based on the conditions\n",
        "    for node in nodes:\n",
        "        x[node] = 0.5  # Test nodes\n",
        "    for node in btrain:\n",
        "        x[node] = 0  # Benign training nodes\n",
        "    for node in strain:\n",
        "        x[node] = 1  # Sybil training nodes\n",
        "\n",
        "\n",
        "    # Create the PyTorch Geometric data object\n",
        "    data_train = Data(x=x, edge_index=edge_index, y=labels)\n",
        "\n",
        "    # Create subgraphs for training and testing\n",
        "    train_subgraph = create_subgraph(data_train, train_nodes)\n",
        "\n",
        "    xx = x[:]\n",
        "    for node in b_known_in_test_phase:\n",
        "        xx[node] = 0  # Benign training nodes\n",
        "    for node in s_known_in_test_phase:\n",
        "        xx[node] = 1\n",
        "\n",
        "    data_test = Data(x=xx, edge_index=edge_index, y=labels)\n",
        "\n",
        "    test_subgraph = create_subgraph(data_test, test_nodes)\n",
        "\n",
        "    # Define optimizer and loss function\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Training loop\n",
        "    def train():\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(train_subgraph)\n",
        "        loss = loss_fn(out, train_subgraph.y)  # Only consider training nodes for loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        return loss.item()\n",
        "\n",
        "    # Testing function\n",
        "    def test():\n",
        "        model.eval()\n",
        "        out = model(test_subgraph)\n",
        "        pred = out.argmax(dim=1)  # Get predictions\n",
        "        test_acc = accuracy_score(test_subgraph.y.cpu(), pred.cpu())\n",
        "        return test_acc\n",
        "\n",
        "    # Training the model\n",
        "    epochs = 100\n",
        "    for epoch in range(epochs):\n",
        "        loss = train()\n",
        "        test_acc = test()\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch {epoch}, Loss: {loss:.4f}, Test Acc: {test_acc:.4f}')\n",
        "\n",
        "    # Final evaluation\n",
        "    test_acc = test()\n",
        "    print(f'Final Test Accuracy: {test_acc:.4f}')\n",
        "\n",
        "\n",
        "    return train_subgraph,test_subgraph,x,xx\n"
      ],
      "metadata": {
        "id": "_U_XGHAdMUdB"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_subgraph,test_subgraph,x,xx = main_inductive(GCN2(num_node_features=1, hidden_dim1=16, hidden_dim2 = 16, num_classes=2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J38v2yxBQ4W6",
        "outputId": "380c7ea5-2808-4133-b55c-7408a6a880a4"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6512, Test Acc: 0.8969\n",
            "Epoch 10, Loss: 0.4147, Test Acc: 0.8969\n",
            "Epoch 20, Loss: 0.3668, Test Acc: 0.8969\n",
            "Epoch 30, Loss: 0.3628, Test Acc: 0.8969\n",
            "Epoch 40, Loss: 0.3623, Test Acc: 0.8969\n",
            "Epoch 50, Loss: 0.3621, Test Acc: 0.8969\n",
            "Epoch 60, Loss: 0.3621, Test Acc: 0.8969\n",
            "Epoch 70, Loss: 0.3621, Test Acc: 0.8969\n",
            "Epoch 80, Loss: 0.3621, Test Acc: 0.8969\n",
            "Epoch 90, Loss: 0.3621, Test Acc: 0.8969\n",
            "Final Test Accuracy: 0.8969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def temp(x):\n",
        "    unique_elements, counts = torch.unique(x, return_counts=True)\n",
        "\n",
        "    # Print unique elements and their frequency\n",
        "    for element, count in zip(unique_elements, counts):\n",
        "        print(f\"Element: {element}, Frequency: {count}\")"
      ],
      "metadata": {
        "id": "yatjbVDtjUXK"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp(train_subgraph.y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nz6krAggjKYN",
        "outputId": "7d9f8ff5-41d3-447c-cbfb-07d99f2d715a"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element: 0, Frequency: 49\n",
            "Element: 1, Frequency: 960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp(test_subgraph.y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkTxp7LijQPv",
        "outputId": "529bdd78-0764-4689-a9fe-0916274b6ae8"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element: 0, Frequency: 354\n",
            "Element: 1, Frequency: 3079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akqasaZ1kcGf",
        "outputId": "29b358a5-1d59-4da7-c245-ee6880d5f65d"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element: 0.0, Frequency: 80\n",
            "Element: 0.5, Frequency: 4282\n",
            "Element: 1.0, Frequency: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp(xx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9Nem5zHkm3H",
        "outputId": "e94c462e-bc1e-43d4-81c7-238df6be1987"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Element: 0.0, Frequency: 80\n",
            "Element: 0.5, Frequency: 4282\n",
            "Element: 1.0, Frequency: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_inductive(GAT1(num_node_features=1, hidden_dim1=4, hidden_dim2=4, num_classes=2, num_heads=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsIGxzCFQ9Lt",
        "outputId": "260a99b7-d5c4-4720-97c4-2e9786e4ab77"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.6352, Test Acc: 0.8978\n",
            "Epoch 10, Loss: 0.2129, Test Acc: 0.8978\n",
            "Epoch 20, Loss: 0.2131, Test Acc: 0.8978\n",
            "Epoch 30, Loss: 0.2072, Test Acc: 0.8978\n",
            "Epoch 40, Loss: 0.2041, Test Acc: 0.8978\n",
            "Epoch 50, Loss: 0.2031, Test Acc: 0.8978\n",
            "Epoch 60, Loss: 0.2030, Test Acc: 0.8978\n",
            "Epoch 70, Loss: 0.2030, Test Acc: 0.8978\n",
            "Epoch 80, Loss: 0.2030, Test Acc: 0.8978\n",
            "Epoch 90, Loss: 0.2030, Test Acc: 0.8978\n",
            "Final Test Accuracy: 0.8978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_inductive(GAT_ETH(input_width=1, num_layers=4, hidden_width=16, num_classes=2, num_heads=8, dropout= True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "sB-1gGrHSvUn",
        "outputId": "2845ac6b-67fc-4b0a-d72b-b117e269b59d"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.7685, Test Acc: 0.8980\n",
            "Epoch 10, Loss: 0.2275, Test Acc: 0.8980\n",
            "Epoch 20, Loss: 0.2392, Test Acc: 0.8980\n",
            "Epoch 30, Loss: 0.2406, Test Acc: 0.8980\n",
            "Epoch 40, Loss: 0.2116, Test Acc: 0.8980\n",
            "Epoch 50, Loss: 0.2136, Test Acc: 0.8980\n",
            "Epoch 60, Loss: 0.2157, Test Acc: 0.8980\n",
            "Epoch 70, Loss: 0.2104, Test Acc: 0.8980\n",
            "Epoch 80, Loss: 0.2064, Test Acc: 0.8980\n",
            "Epoch 90, Loss: 0.2133, Test Acc: 0.8980\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-201-a12634a145a5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain_inductive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGAT_ETH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-195-71bb79023dc5>\u001b[0m in \u001b[0;36mmain_inductive\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-195-71bb79023dc5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_subgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_subgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Only consider training nodes for loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O0rB-zqHeAz5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}